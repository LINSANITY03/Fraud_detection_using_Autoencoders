{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook for model training\n",
    "\n",
    "# This notebook trains and evaluates machine learning models on the preprocessed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path from config file\n",
    "\n",
    "import yaml\n",
    "\n",
    "with open(\"../../config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "\n",
    "raw_data_path = \"../../\" + config[\"paths\"][\"raw_data\"]\n",
    "processed_data_path = \"../../\" + config[\"paths\"][\"processed_data\"]\n",
    "learning_rate = float(config[\"model\"][\"learning_rate\"])\n",
    "epoch = int(config[\"model\"][\"epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284315, 29)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(processed_data_path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will train the model on normal data only (unsupervised learning)\n",
    "X_train = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the AutoEncoder\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder part\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(29, 14),  # Input layer (29 features) -> hidden layer (14 features)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(14, 7),   # Hidden layer -> smaller hidden layer (7 features)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(7, 3),    # Bottleneck layer (compressed representation)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder part\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 7),    # Bottleneck layer -> hidden layer (7 features)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(7, 14),   # Hidden layer -> hidden layer (14 features)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(14, 29),  # Hidden layer -> output layer (29 features)\n",
    "            nn.Sigmoid()        # To bring the output in range [0,1] (same as input range)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to torch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = Autoencoder()\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for reconstruction\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/9], Loss: 1.1612\n",
      "Epoch [20/19], Loss: 1.1333\n",
      "Epoch [30/29], Loss: 1.1030\n",
      "Epoch [40/39], Loss: 1.0769\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store logs\n",
    "logs = []\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epoch):\n",
    "    model.train()  # Ensure the model is in training mode\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(X_train_tensor) # automatically calls model.forward\n",
    "    loss = criterion(output, X_train_tensor)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        logs.append({\"Epoch\": f'[{epoch+1}/{epoch}]', \"train_loss\": loss.item()})\n",
    "        print(f'Epoch [{epoch+1}/{epoch}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Save logs to CSV\n",
    "pd.DataFrame(logs).to_csv(\"../../models/model_logs/autoencoder_training_logs.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "\n",
    "torch.save(model.state_dict(), \"../../models/saved_models/autoencoder_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
